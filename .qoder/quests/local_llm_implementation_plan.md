# Задача для Qoder агента: Реализация поддержки локальных LLM и улучшение функциональности ИИ-чата

## Обзор задачи

Эта задача направлена на расширение функциональности системы расчета коэффициентов усушки путем реализации поддержки локальных LLM моделей и улучшения ИИ-чата. В рамках задачи необходимо реализовать интеграцию с LM Studio, OpenRouter и добавить поддержку русскоязычных моделей.

## Цели задачи

1. Реализовать поддержку локальных LLM моделей через LM Studio
2. Интегрировать OpenRouter как провайдера ИИ моделей
3. Добавить поддержку русскоязычных моделей
4. Улучшить ИИ-чат с возможностью выбора между разными типами ИИ
5. Обеспечить совместимость с существующими настройками

## Технические требования

### 1. Расширение класса AIChat

#### 1.1. Добавить новые параметры конфигурации:
- `enable_local_ai` (bool) - включение локального ИИ
- `local_ai_model` (str) - название модели для локального ИИ
- `local_ai_base_url` (str) - URL сервера LM Studio (по умолчанию "http://localhost:1234/v1")
- `enable_openrouter` (bool) - включение использования OpenRouter
- `openrouter_api_key` (str) - API ключ для OpenRouter
- `openrouter_model` (str) - модель для использования через OpenRouter

#### 1.2. Добавить методы:
- `get_local_ai_response()` - для обработки запросов к локальному ИИ через LM Studio
- `get_openrouter_response()` - для обработки запросов к OpenRouter
- Обновить метод `get_response()` для поддержки выбора между разными типами ИИ

### 2. Интеграция с LM Studio

#### 2.1. Реализовать поддержку API LM Studio:
- Совместимость с OpenAI API форматом
- Поддержка различных моделей (Llama, Qwen, Gemma и др.)
- Обработка ошибок подключения к серверу

#### 2.2. Рекомендации по выбору моделей:
- Для ограниченных ресурсов (8 ГБ RAM): Qwen3 4B, Gemma3 4B
- Для средних конфигураций (16 ГБ RAM): Llama 3 8B, Qwen3 8B, Gemma3 8B
- Для мощных конфигураций (32+ ГБ RAM): Llama 3 70B, Mixtral 8x7B

#### 2.3. Русскоязычные модели для локального использования:
- Qwen3 8B/72B - отличная поддержка русского языка
- Gemma3 8B - хорошая поддержка русского языка
- ruGPT-3.5 - специализированная русскоязычная модель
- Siberian Mouse - русскоязычная модель от DeepPavlov
- Vikhr-Qwen-2.5-0.5B-instruct - обученная на русском языке

### 3. Интеграция с OpenRouter

#### 3.1. Реализовать поддержку OpenRouter API:
- Совместимость с OpenAI API форматом
- Поддержка более чем 400 различных моделей
- Автоматическое распределение нагрузки между провайдерами

#### 3.2. Поддерживаемые модели:
- OpenAI (GPT-3.5, GPT-4, GPT-4 Turbo)
- Claude (Anthropic)
- Google (PaLM 2, Gemini Pro)
- Meta (Llama 2, Llama 3, Code Llama)
- Mistral AI (Mistral 7B, Mixtral 8x7B)
- Alibaba (Qwen)
- DeepSeek (DeepSeek)
- Google (Gemma)

### 4. Обновление графического интерфейса

#### 4.1. Tkinter GUI:
- Обновить диалог настроек ИИ-чата
- Добавить выбор типа ИИ (встроенный, внешний, локальный, OpenRouter)
- Добавить поля настройки для LM Studio и OpenRouter

#### 4.2. Flet GUI:
- Обновить диалог настроек ИИ-чата
- Добавить выбор типа ИИ
- Добавить поля настройки для LM Studio и OpenRouter

### 5. Обновление конфигурации

#### 5.1. Обновить src/config.py:
- Добавить новые параметры конфигурации для локального ИИ и OpenRouter
- Обновить валидационные правила

#### 5.2. Обновить документацию:
- Документация ai_chat_functionality.md
- Обновить примеры использования

## План реализации

### Этап 1: Подготовка (1 день)
- Анализ существующего кода AIChat
- Подготовка структуры для новых функций
- Создание тестовой среды

### Этап 2: Реализация базовой функциональности (2 дня)
- Расширение класса AIChat
- Добавление поддержки локального ИИ через LM Studio
- Добавление поддержки OpenRouter
- Обновление логики выбора типа ИИ

### Этап 3: Интеграция с GUI (2 дня)
- Обновление Tkinter GUI
- Обновление Flet GUI
- Тестирование интерфейса

### Этап 4: Тестирование и отладка (1 день)
- Тестирование всех типов ИИ
- Проверка обратной совместимости
- Отладка ошибок

### Этап 5: Документация и финальное тестирование (1 день)
- Обновление документации
- Финальное тестирование
- Подготовка руководства пользователя

## Критерии приемки

1. Система поддерживает все четыре типа ИИ:
   - Встроенный ИИ (без подключения к интернету)
   - Внешний ИИ (через OpenAI API совместимые сервисы)
   - Локальный ИИ (через LM Studio)
   - OpenRouter (через OpenRouter API)

2. Все типы ИИ корректно работают с русским языком

3. Интерфейс позволяет выбирать между разными типами ИИ

4. Настройки каждого типа ИИ сохраняются и загружаются корректно

5. Система корректно обрабатывает ошибки подключения и отсутствия моделей

6. Документация обновлена и содержит информацию о новых возможностях

## Рекомендации по реализации

1. Использовать существующую архитектуру класса AIChat как основу
2. Сохранить обратную совместимость с существующими настройками
3. Реализовать обработку ошибок для всех типов подключения
4. Использовать асинхронные вызовы для улучшения отзывчивости интерфейса
5. Добавить логирование для упрощения отладки
6. Протестировать работу с разными моделями и провайдерами

## Приоритетные модели для тестирования

### Русскоязычные модели:
1. Qwen3 8B (рекомендуемая для средних конфигураций)
2. Gemma3 8B
3. ruGPT-3.5
4. Vikhr-Qwen-2.5-0.5B-instruct (специализированная русская модель)

### Англоязычные модели:
1. Llama 3 8B (универсальная модель)
2. Mistral 7B
3. Gemma 2 9B

## Требования к производительности

1. Время отклика ИИ не должно превышать 30 секунд для локальных моделей
2. Система должна корректно обрабатывать прерывания запросов
3. При отсутствии подключения система должна использовать встроенный ИИ
4. Логирование должно содержать информацию о времени выполнения запросов

## Тестирование

1. Модульные тесты для новых методов класса AIChat
2. Интеграционные тесты для каждого типа ИИ
3. Тесты пользовательского интерфейса
4. Тесты обратной совместимости
5. Тесты обработки ошибок

## Документация

1. Обновить документацию ai_chat_functionality.md
2. Добавить руководство по настройке LM Studio
3. Добавить руководство по использованию OpenRouter
4. Обновить примеры конфигурации
5. Добавить рекомендации по выбору моделей в зависимости от аппаратных характеристик

## Риски и меры по их минимизации

1. **Риск**: Несовместимость с некоторыми версиями LM Studio
   **Мера**: Реализовать обработку ошибок и предоставить подробные инструкции по настройке

2. **Риск**: Проблемы с производительностью локальных моделей
   **Мера**: Добавить рекомендации по выбору моделей в зависимости от аппаратных характеристик

3. **Риск**: Изменения в API OpenRouter
   **Мера**: Реализовать гибкую систему обработки API и регулярное тестирование

4. **Риск**: Проблемы с русскоязычными моделями
   **Мера**: Протестировать несколько моделей и предоставить рекомендации по выбору