#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ê–Ω–∞–ª–∏–∑ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –¥–∞–Ω–Ω—ã—Ö —Å –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–µ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤ —É—Å—É—à–∫–∏

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –≤—ã–ø–æ–ª–Ω—è–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ñ–∞–π–ª–∞ –∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö.
"""

import sys
import os
import pandas as pd
import json
import numpy as np

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ src –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../src')))

from core.shrinkage_system import ShrinkageSystem
from core.shrinkage_verification_system import ShrinkageVerificationSystem


def analyze_file_structure(file_path):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ñ–∞–π–ª–∞ –∏ –≤—ã–≤–æ–¥–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞–Ω–Ω—ã—Ö."""
    print(f"üîç –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ñ–∞–π–ª–∞: {file_path}")
    print("=" * 60)
    
    # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª –±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
    df = pd.read_excel(file_path, header=None)
    print(f"üìä –û–±—â–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–∞:")
    print(f"   –°—Ç—Ä–æ–∫: {df.shape[0]}, –°—Ç–æ–ª–±—Ü–æ–≤: {df.shape[1]}")
    
    # –í—ã–≤–æ–¥–∏–º –ø–µ—Ä–≤—ã–µ 10 —Å—Ç—Ä–æ–∫ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
    print(f"\nüìã –ü–µ—Ä–≤—ã–µ 10 —Å—Ç—Ä–æ–∫ —Ñ–∞–π–ª–∞:")
    print(df.head(10).to_string())
    
    # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞–º–∏
    # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã —Å–æ–¥–µ—Ä–∂–∞—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
    keywords = ['–†–´–ë–ê', '–°–ï–õ–¨–î–¨', '–°–ö–£–ú–ë–†–ò–Ø', '–©–£–ö–ê', '–û–ö–£–ù–¨', '–ì–û–†–ë–£–®–ê', '–ö–ï–¢–ê', '–°–ï–ú–ì–ê', 
                '–§–û–†–ï–õ–¨', '–ò–ö–†–ê', '–ö–†–ï–í–ï–¢–ö–ò', '–ú–ê–°–õ–ï–ù–ê–Ø', '–ù–ï–†–ö–ê', '–ú–û–ô–í–ê', '–Æ–ö–û–õ–ê', '–í–û–ú–ï–†',
                '–ë–†–Æ–®–ö–ò', '–ö–û–†–Æ–®–ö–ê', '–õ–ï–©', '–°–ò–ì', '–î–û–†–ê–î–û', '–ë–ï–õ–û–†–´–ë–ò–¶–ê', '–¢–ê–†–ê–ù–¨', '–ß–ï–•–û–ù–¨',
                '–ü–ï–õ–Ø–î–¨', '–í–û–ë–õ–ê', '–ö–ê–ú–ë–ê–õ–ê', '–•/–ö', '–ì/–ö', '–°/–°', '–í–Ø–õ–ï–ù']
    
    product_mask = df[0].astype(str).str.contains('|'.join(keywords), case=False, na=False)
    product_rows = df[product_mask]
    
    print(f"\nüêü –ù–∞–π–¥–µ–Ω–æ —Å—Ç—Ä–æ–∫ —Å –ø—Ä–æ–¥—É–∫—Ç–∞–º–∏: {len(product_rows)}")
    
    if len(product_rows) > 0:
        print(f"\nüìã –ü—Ä–∏–º–µ—Ä—ã —Å—Ç—Ä–æ–∫ —Å –ø—Ä–æ–¥—É–∫—Ç–∞–º–∏:")
        print(product_rows.head().to_string())
    
    return df


def extract_product_data(df):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–¥—É–∫—Ç–∞—Ö –∏–∑ DataFrame."""
    print(f"\nüîß –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥—É–∫—Ç–∞—Ö...")
    
    # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–¥—É–∫—Ç–∞–º–∏
    keywords = ['–†–´–ë–ê', '–°–ï–õ–¨–î–¨', '–°–ö–£–ú–ë–†–ò–Ø', '–©–£–ö–ê', '–û–ö–£–ù–¨', '–ì–û–†–ë–£–®–ê', '–ö–ï–¢–ê', '–°–ï–ú–ì–ê', 
                '–§–û–†–ï–õ–¨', '–ò–ö–†–ê', '–ö–†–ï–í–ï–¢–ö–ò', '–ú–ê–°–õ–ï–ù–ê–Ø', '–ù–ï–†–ö–ê', '–ú–û–ô–í–ê', '–Æ–ö–û–õ–ê', '–í–û–ú–ï–†',
                '–ë–†–Æ–®–ö–ò', '–ö–û–†–Æ–®–ö–ê', '–õ–ï–©', '–°–ò–ì', '–î–û–†–ê–î–û', '–ë–ï–õ–û–†–´–ë–ò–¶–ê', '–¢–ê–†–ê–ù–¨', '–ß–ï–•–û–ù–¨',
                '–ü–ï–õ–Ø–î–¨', '–í–û–ë–õ–ê', '–ö–ê–ú–ë–ê–õ–ê', '–•/–ö', '–ì/–ö', '–°/–°', '–í–Ø–õ–ï–ù']
    
    product_mask = df[0].astype(str).str.contains('|'.join(keywords), case=False, na=False)
    product_rows = df[product_mask]
    
    product_data = []
    
    # –î–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–¥—É–∫—Ç–æ–º –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ
    for index, row in product_rows.iterrows():
        try:
            # –ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞ (–ø–µ—Ä–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü)
            nomenclature = str(row.iloc[0]) if len(row) > 0 else f"–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞_{index}"
            
            # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É: —Å—Ç–æ–ª–±—Ü—ã 4, 6, 7, 8 —Å–æ–¥–µ—Ä–∂–∞—Ç –¥–∞–Ω–Ω—ã–µ
            initial_balance = pd.to_numeric(row.iloc[4], errors='coerce') if len(row) > 4 else np.nan
            incoming = pd.to_numeric(row.iloc[6], errors='coerce') if len(row) > 6 else np.nan
            outgoing = pd.to_numeric(row.iloc[7], errors='coerce') if len(row) > 7 else np.nan
            final_balance = pd.to_numeric(row.iloc[8], errors='coerce') if len(row) > 8 else np.nan
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—Ç
            if pd.notna(initial_balance) and pd.notna(incoming) and pd.notna(outgoing) and pd.notna(final_balance):
                # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫—É—é —É—Å—É—à–∫—É
                theoretical_balance = initial_balance + incoming - outgoing
                actual_shrinkage = theoretical_balance - final_balance
                
                product_data.append({
                    '–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞': nomenclature,
                    '–ù–∞—á–∞–ª—å–Ω—ã–π_–æ—Å—Ç–∞—Ç–æ–∫': initial_balance,
                    '–ü—Ä–∏—Ö–æ–¥': incoming,
                    '–†–∞—Å—Ö–æ–¥': outgoing,
                    '–ö–æ–Ω–µ—á–Ω—ã–π_–æ—Å—Ç–∞—Ç–æ–∫': final_balance,
                    '–§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è_—É—Å—É—à–∫–∞': max(0, actual_shrinkage),  # –£—Å—É—à–∫–∞ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–π
                    '–ü–µ—Ä–∏–æ–¥_—Ö—Ä–∞–Ω–µ–Ω–∏—è_–¥–Ω–µ–π': 7  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–µ—Ä–∏–æ–¥
                })
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–æ–∫–∏ {index}: {str(e)}")
            continue
    
    print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(product_data)}")
    return product_data


def process_with_verification(product_data, file_name):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–µ–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤."""
    print(f"\nüßÆ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–µ–π...")
    
    if len(product_data) == 0:
        print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        return
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame
    dataset = pd.DataFrame(product_data)
    print(f"üìä –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
    print(dataset.head().to_string())
    
    # –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º—É —É—Å—É—à–∫–∏
    system = ShrinkageSystem()
    system.config['enable_verification'] = True
    system.config['use_adaptive_model'] = True
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    results = system.process_dataset(
        dataset=dataset,
        source_filename=file_name,
        use_adaptive=True
    )
    
    if results['status'] != 'success':
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {results.get('message', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
        return
    
    print("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏
    coefficients = results.get('coefficients', [])
    print(f"\nüîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ ({len(coefficients)} –∑–∞–ø–∏—Å–µ–π):")
    
    verification_passed = 0
    verification_warning = 0
    verification_critical = 0
    
    for i, coeff in enumerate(coefficients[:10]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        nomenclature = coeff.get('–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞')
        accuracy = coeff.get('–¢–æ—á–Ω–æ—Å—Ç—å_R2', 0)
        verification = coeff.get('–í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è', {})
        
        if verification:
            verification_status = verification.get('verification_status', 'unknown')
            validation_status = verification.get('validation_status', {})
            overall_status = validation_status.get('overall_status', 'unknown')
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å—ã
            if overall_status == 'acceptable':
                verification_passed += 1
            elif overall_status == 'warning':
                verification_warning += 1
            elif overall_status == 'critical':
                verification_critical += 1
            
            print(f"   {i+1:2d}. {nomenclature[:30]:30} | –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:6.2f}% | –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è: {overall_status.upper()}")
        else:
            print(f"   {i+1:2d}. {nomenclature[:30]:30} | –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:6.2f}% | –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è: –ù–ï–¢ –î–ê–ù–ù–´–•")
    
    print(f"\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
    print(f"   –£—Å–ø–µ—à–Ω–æ: {verification_passed}")
    print(f"   –° –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏: {verification_warning}")
    print(f"   –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ: {verification_critical}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    output_dir = "—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"
    os.makedirs(output_dir, exist_ok=True)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –≤ JSON
    coefficients_file = os.path.join(output_dir, f"–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã_—É—Å—É—à–∫–∏_{os.path.splitext(file_name)[0]}_–∞–Ω–∞–ª–∏–∑.json")
    with open(coefficients_file, 'w', encoding='utf-8') as f:
        json.dump(coefficients, f, ensure_ascii=False, indent=2)
    print(f"\nüíæ –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {coefficients_file}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç—ã
    reports = results.get('reports', {})
    for report_name, report_content in reports.items():
        report_file = os.path.join(output_dir, f"{report_name}_–∞–Ω–∞–ª–∏–∑.html")
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        print(f"üíæ –û—Ç—á–µ—Ç '{report_name}' —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {report_file}")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–∞–Ω–Ω—ã—Ö
    file_path = r"C:\Users\D_909\Desktop\–¥–ª—è –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞\–∏—Å—Ö–æ–¥–Ω—ã–µ_–¥–∞–Ω–Ω—ã–µ\–î–ª—è_—Ä–∞—Å—á–µ—Ç–∞_–∫–æ—ç—Ñ—Ñ\b3ded820-4385-4a42-abc7-75dc0756d335_6ba7ac50-fb1a-4bea-9489-265bdfdcb8d1_–≤—Å—è –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞ –∑–∞ –ø–µ—Ä–∏–æ–¥ —Å 15.07.25 –ø–æ 21.07.25.xls"
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ñ–∞–π–ª–∞
    df = analyze_file_structure(file_path)
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–¥—É–∫—Ç–∞—Ö
    product_data = extract_product_data(df)
    
    if len(product_data) > 0:
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–µ–π
        file_name = os.path.basename(file_path)
        process_with_verification(product_data, file_name)
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–¥—É–∫—Ç–∞—Ö")


if __name__ == "__main__":
    main()